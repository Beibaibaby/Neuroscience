# HB-Learning

> This repo has learnt a lot from [this repo](https://github.com/Adoni/word2vec_pytorch) and https://github.com/PengFoo/word2vec-pytorch

This repo implements the **SkipGram model with negative sampling** of Word2vec and **HB-learning** defined by Kaer Di and Draco Xu.

# Hebbian theory based Generator
![image](https://user-images.githubusercontent.com/56213541/121285192-87cdc000-c910-11eb-9742-e1292758bcac.png)
run 
`python godfather_net.py` 

# Requirements
- PyTorch >= 0.4.1
- Gensim >= 3.6.0 (for testing only)


# Reference
[1] Mikolov T, Sutskever I, Chen K, et al. Distributed representations of words and phrases and their compositionality[C]//Advances in neural information processing systems. 2013: 3111-3119.
